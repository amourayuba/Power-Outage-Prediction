{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec023bbb-e26f-4ae5-b6c0-aa312e3b7fbc",
   "metadata": {},
   "source": [
    "# Cleaning and merging weather and power data\n",
    "This file contains general purpose scripts for downloading, cleaning, and merging weather and power data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17e9339c-7312-4ada-a779-b6839e8f1e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import reverse_geocoder as rg\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ftplib\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "\n",
    "pd.options.mode.copy_on_write = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfd4ee1-9b10-4f03-b118-84e714ac05e5",
   "metadata": {},
   "source": [
    "## Automatic downloading and reading of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55206573-6171-4de0-8e03-3717ed274ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_types = {'hail':'hail', 'storm_structure':'structure', 'tornados':'tvs', 'lightning':'nldn-tiles', 'mesocyclone':'mda'}\n",
    "for event in event_types:\n",
    "    path = '../../weather_data/'+event\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27b3e854-67ad-44a2-937d-a2c86ad0991b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to the server\n",
    "ftp = ftplib.FTP('ftp.ncdc.noaa.gov', timeout=30) #pass the url without protocol\n",
    "ftp.login() #pass credentials if anonymous access is not allowed\n",
    "\n",
    "# switch to the directory containing the data\n",
    "ftp.cwd('/pub/data/swdi/database-csv/v2/')\n",
    "ftp.pwd()\n",
    "\n",
    "httpurl = 'https://www.ncei.noaa.gov/pub/data/swdi/database-csv/v2/'\n",
    "# get the list of files in this ftp dir\n",
    "all_files= ftp.nlst()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ebd25ab-9285-49f9-b34c-e41214431795",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_weather(year, event_type):\n",
    "    print(f'Downloading {event_type} file for {year}.')\n",
    "    event_name = event_types[event_type]\n",
    "    pattern = event_name+\"-\"+str(year)\n",
    "    file_name = [fname for fname in all_files if pattern in fname]\n",
    "    if len(file_name) == 0:\n",
    "        print(\"No file in that year for that event type\" )\n",
    "        return \n",
    "    file_name = file_name[0]\n",
    "    print(\"Considering file \", file_name)\n",
    "    if os.path.exists('../../weather_data/{}/{}'.format(event_type, file_name)):\n",
    "        print(\"file already exists\")\n",
    "        return \n",
    "    query_parameters = {\"downloadformat\": \"csv\"}\n",
    "    print(\"Getting the response from the URL .....\")\n",
    "    response = requests.get(httpurl+file_name, params=query_parameters)\n",
    "    if response.ok:\n",
    "        print(\"Downloaded succesfully\")\n",
    "    with open(r'../../weather_data/{}/{}'.format(event_type, file_name), \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "    print('Saved in folder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1085542-bf79-4235-89b9-27c775290d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_weather(year, event_type):\n",
    "    download_weather(year,event_type)\n",
    "    files = os.listdir('../../weather_data/'+event_type)\n",
    "    file_name = [fname for fname in files if str(year) in fname]\n",
    "    if len(file_name) == 0:\n",
    "        raise Exception(f\"No file for event type {event_type} in year {year}\") \n",
    "    if len(file_name) > 1:\n",
    "        raise Exception(f\"Multiple files for event type {event_type} in year {year}\")\n",
    "    if event_type == 'lightning' or event_type == 'tornado':\n",
    "        return pd.read_csv(r'../../weather_data/'+event_type+'/'\n",
    "                  + file_name[0], skiprows=2, parse_dates=['#ZDAY'])\n",
    "    return pd.read_csv(r'../../weather_data/'+event_type+'/'\n",
    "                  + file_name[0], skiprows=2, parse_dates=['#ZTIME'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012fedfa-494d-4ead-8c74-b078d1251d25",
   "metadata": {},
   "source": [
    "## Cleaning power data\n",
    "We clean the power data as follows.\n",
    "1. Convert 'Date Event Began' column to datetime format.\n",
    "2. Keep only the rows where power event type involves 'Severe Weather'.\n",
    "3. Drop all columns except Date Event Began and Area Affected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3338c728-a58f-4e70-a602-12c71cee296b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_power(power):\n",
    "    power['Date Event Began'] = pd.to_datetime(power['Date Event Began'], format='%m/%d/%Y')\n",
    "    power = power[power['Event Type'].str.contains(r'Severe Weather', regex=True)]\n",
    "    return power.drop(columns=['Month', 'Time Event Began', 'Date of Restoration', 'Time of Restoration', \n",
    "                         'NERC Region', 'Alert Criteria', 'Event Type', 'Demand Loss (MW)', 'Number of Customers Affected'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81680192-a3bb-469d-bfe1-81c79c350866",
   "metadata": {},
   "source": [
    "## Cleaning weather data\n",
    "We clean weather data as follows.\n",
    "1. Convert '#ZDAY' or '#ZTIME' column to 'DATE' column in datetime format, and add a separate 'MONTH' column as well.\n",
    "2. Split into groups by 'DATE', 'WSR_ID', and 'CELL_ID', then get the mean of 'LAT' and 'LON' in each group, and the max for each remaining attribute in each group. (For lightning data, this step is not necessary.)\n",
    "3. Reverse geosearch using 'LAT' and 'LON' to get 'COUNTY' and 'STATE' columns.\n",
    "4. Drop the rows where no county info is found (indicating an event outside of the US)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08ac61ba-4b8a-440f-af9b-fd31c364f290",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date(weather):\n",
    "    weather['DATE'] = pd.to_datetime(weather['#ZTIME']).dt.normalize()\n",
    "    weather['MONTH'] = weather['DATE'].dt.month\n",
    "    return weather.drop(columns=['#ZTIME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ebb388b-1c29-4cfe-80ab-e6368f536b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_groups(weather, attributes):\n",
    "    groups = weather.groupby(['DATE', 'MONTH', 'WSR_ID', 'CELL_ID'], as_index=False)\n",
    "    return groups.agg(attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9486f20-d1d3-4aa6-bd42-b4e7d598baf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_county_and_state(weather):\n",
    "    addresses = rg.search(list(zip(weather['LAT'], weather['LON'])))\n",
    "    weather['COUNTY'] = [x['admin2'] for x in addresses]\n",
    "    weather['STATE'] = [x['admin1'] for x in addresses]\n",
    "    return weather[weather['COUNTY'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc52b2fc-ca92-481a-885d-64ed4c2330ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_lightning(lightning):\n",
    "    lightning.rename(columns={'#ZDAY' : '#ZTIME', 'CENTERLAT': 'LAT', 'CENTERLON': 'LON'}, inplace=True)\n",
    "    lightning_dates = get_date(lightning)\n",
    "    return get_county_and_state(lightning_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5555aa2d-2f38-461c-88f4-741fbd8a4eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tornado(tornados):\n",
    "    tornados_dates = get_date(tornados)\n",
    "    tornados_aggregate = aggregate_groups(tornados_dates, {'LAT':'mean',\n",
    "                                                           'LON':'mean',\n",
    "                                                           'AVGDV':'max', 'LLDV':'max', 'MXDV':'max',\n",
    "                                                           'MXDV_HEIGHT':'max', 'DEPTH':'max',\n",
    "                                                           'MAX_SHEAR':'max', 'MAX_SHEAR_HEIGHT':'max'})\n",
    "    tor_agg = get_county_and_state(tornados_aggregate)\n",
    "    return tor_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14da3c66-da23-49ef-b0ec-3a5b1d198819",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_hail(hail):\n",
    "    hail = hail[hail.SEVPROB>0]\n",
    "    hail_dates = get_date(hail)\n",
    "    hail_aggregate = aggregate_groups(hail_dates, {'LAT':'mean', \n",
    "                                                   'LON':'mean',\n",
    "                                                   'SEVPROB':'max', 'PROB':'max', 'MAXSIZE':'max'})\n",
    "    hail_agg = get_county_and_state(hail_aggregate)\n",
    "    return hail_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00d86171-2fbe-4e6f-b325-37f34ffda8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_meso(meso):\n",
    "    meso_dates = get_date(meso)\n",
    "    meso_aggregate = aggregate_groups(meso_dates, {'LAT':'mean', \n",
    "                                                  'LON':'mean', \n",
    "                                                  'STR_RANK':'max', 'LL_ROT_VEL':'max', \n",
    "                                                  'LL_DV':'max', 'LL_BASE':'max', 'DEPTH_KFT':'max', \n",
    "                                                  'DPTH_STMRL':'max', 'MAX_RV_KFT':'max', 'MAX_RV_KTS':'max', \n",
    "                                                  'TVS':'max', 'MSI':'max'})\n",
    "    meso_agg = get_county_and_state(meso_aggregate)\n",
    "    return meso_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2a4a558-8cfc-4843-8200-aee8c2bc3110",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_storm(storm):\n",
    "    storm_dates = get_date(storm)\n",
    "    storm_aggregate = aggregate_groups(storm_dates, {'LAT':'mean',\n",
    "                                                     'LON':'mean',\n",
    "                                                     'MAX_REFLECT':'max', 'VIL':'max', 'HEIGHT':'max'})\n",
    "    storm_agg = get_county_and_state(storm_aggregate)\n",
    "    return storm_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec52a67-86b2-46f4-86b6-ef3c6a7201be",
   "metadata": {},
   "source": [
    "## Merging\n",
    "We merge cleaned weather data with cleaned power data by adding a column specifying whether or not the recorded weather event resulted in a power outage in the same area on the same date. 'In the same area' is explained in the in_area function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cbd012-673c-44b0-b0aa-0ea24ab2fff4",
   "metadata": {},
   "source": [
    "### Checking if weather and power event are in same county, or state if no county info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc180bde-7225-4a82-975d-4a9dff26525c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all US states\n",
    "counties = pd.read_csv(\"../../county_data/uscounties.csv\", index_col=0)\n",
    "counties['county'] = counties['county'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a562ebfe-65e3-40d1-b03a-f93b338dd977",
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_area(county, state, area_affected):\n",
    "    \"\"\"\n",
    "    input:\n",
    "\n",
    "    county, state: the county and state of the weather event\n",
    "    area_affected: the area affected by the power outage(a string listing states and possibly counties)\n",
    "    has_county_info: whether area_affected\n",
    "\n",
    "    output: True if either state and county are both in area_affected, or\n",
    "            False if state is in area_affected and there is no county info for area_affected\n",
    "    \"\"\"\n",
    "    if not county or not state or not area_affected:\n",
    "        raise Exception(f\"Invalid (null) input. county: {county}, state: {state}, area_affected: {area_affected}\")\n",
    "\n",
    "    # adding a colon to state ensures that it's matched exactly to a state in area_affected\n",
    "    # (rather than a county whose name is a state)\n",
    "    stateC = ''.join([state,':'])\n",
    "\n",
    "    # has_county_info is True if area_affected includes a county, false otherwise\n",
    "    has_county_info = any(cty in area_affected for cty in counties[counties['state'] == state]['county'])\n",
    "    \n",
    "    return stateC in area_affected and (county in area_affected or not has_county_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f8e9c4-a947-4ae5-9134-810ec5985bfb",
   "metadata": {},
   "source": [
    "### Merging weather and power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0ba5a53-f99c-437c-8901-d019fac7314c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_weather_power(weather, power, light=True):\n",
    "    \"\"\"\n",
    "    Merge weather and power data.\n",
    "\n",
    "    Assumes that the input data are already cleaned.\n",
    "    \"\"\"\n",
    "    merged = pd.merge(weather, power, how='left', left_on='DATE', right_on='Date Event Began', indicator=True)\n",
    "    merged['POWER_OUTAGE'] = merged.apply(lambda row: (row['_merge'] == 'both') and in_area(str(row['COUNTY']),\n",
    "                                                                                            str(row['STATE']),\n",
    "                                                                                            str(row['Area Affected'])),\n",
    "                                          axis = 'columns')\n",
    "    if light:\n",
    "        try:\n",
    "            return merged.drop(columns=['Date Event Began', 'Area Affected', '_merge', 'WSR_ID', 'CELL_ID'])\n",
    "        except KeyError:\n",
    "            return merged.drop(columns=['Date Event Began', 'Area Affected', '_merge'])\n",
    "    return merged.drop(columns=['Date Event Began', 'Area Affected', '_merge'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e82726a0-36f5-4e2c-8854-dcd1d6d009c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(year, event_type):\n",
    "    weather = read_weather(year,event_type)\n",
    "    if event_type == 'hail':\n",
    "        weather = clean_hail(weather)\n",
    "    elif event_type == 'storm_structure':\n",
    "        weather = clean_storm(weather)\n",
    "    elif event_type == 'tornados':\n",
    "        weather = clean_tornado(weather)\n",
    "    elif event_type == 'lightning':\n",
    "        weather = clean_lightning(weather)\n",
    "    elif event_type == 'mesocyclone':\n",
    "        weather = clean_meso(weather)\n",
    "    else:\n",
    "        raise Exception(f'Invalid event type: {event_type}, must be one of {event_types.keys()}')\n",
    "    power= pd.read_excel('../../power_data/' + str(year) + '_Annual_Summary.xls', skiprows=1)\n",
    "    power = clean_power(power)\n",
    "    return merge_weather_power(weather,power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3ca7926-2e31-4e8e-bb9c-9869166e50c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading mesocyclone file for 2019.\n",
      "Considering file  mda-2019.csv.gz\n",
      "file already exists\n",
      "Loading formatted geocoded file...\n",
      "WARNING *** file size (96452) not 512 + multiple of sector size (512)\n"
     ]
    }
   ],
   "source": [
    "merged_meso = merge(2019,'mesocyclone')\n",
    "merged_meso.to_csv(f'../../merged/merged_meso_2019.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce6c2f0b-d807-44bc-8d97-49614d84da79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'read_weather' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:2\u001b[0m\n",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m, in \u001b[0;36mmerge\u001b[0;34m(year, event_type)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(year, event_type):\n\u001b[0;32m----> 2\u001b[0m     weather \u001b[38;5;241m=\u001b[39m \u001b[43mread_weather\u001b[49m(year,event_type)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m event_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhail\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m      4\u001b[0m         weather \u001b[38;5;241m=\u001b[39m clean_hail(weather)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'read_weather' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for year in range(2015,2023):\n",
    "    merged_hail = merge(year,'hail')\n",
    "    merged_hail.to_csv(f'../../merged/merged_hail_{year}.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff7ff90d-6a14-4988-b94d-5e2219e151f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading storm_structure file for 2020.\n",
      "Considering file  structure-2020.csv.gz\n",
      "Getting the response from the URL .....\n",
      "Downloaded succesfully\n",
      "Saved in folder\n",
      "WARNING *** file size (120004) not 512 + multiple of sector size (512)\n",
      "CPU times: user 9min 25s, sys: 8.51 s, total: 9min 34s\n",
      "Wall time: 10min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "merged_storm_2020 = merge(2020,'storm_structure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d513e3b-849b-4ba6-8fcf-14b48d2cb1d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>MAX_REFLECT</th>\n",
       "      <th>VIL</th>\n",
       "      <th>HEIGHT</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>STATE</th>\n",
       "      <th>POWER_OUTAGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>45.531415</td>\n",
       "      <td>-98.985618</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>3.2</td>\n",
       "      <td>Edmunds County</td>\n",
       "      <td>South Dakota</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>45.057635</td>\n",
       "      <td>-98.531035</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>Spink County</td>\n",
       "      <td>South Dakota</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>45.122425</td>\n",
       "      <td>-97.951135</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>2.1</td>\n",
       "      <td>Clark County</td>\n",
       "      <td>South Dakota</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>45.072180</td>\n",
       "      <td>-97.959420</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>Clark County</td>\n",
       "      <td>South Dakota</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>24.273560</td>\n",
       "      <td>-80.413000</td>\n",
       "      <td>47</td>\n",
       "      <td>6</td>\n",
       "      <td>8.8</td>\n",
       "      <td>Monroe County</td>\n",
       "      <td>Florida</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        DATE  MONTH        LAT        LON  MAX_REFLECT  VIL  HEIGHT  \\\n",
       "0 2020-01-01      1  45.531415 -98.985618           38    1     3.2   \n",
       "1 2020-01-01      1  45.057635 -98.531035           38    0     2.9   \n",
       "2 2020-01-01      1  45.122425 -97.951135           40    1     2.1   \n",
       "3 2020-01-01      1  45.072180 -97.959420           35    0     2.2   \n",
       "4 2020-01-01      1  24.273560 -80.413000           47    6     8.8   \n",
       "\n",
       "           COUNTY         STATE  POWER_OUTAGE  \n",
       "0  Edmunds County  South Dakota         False  \n",
       "1    Spink County  South Dakota         False  \n",
       "2    Clark County  South Dakota         False  \n",
       "3    Clark County  South Dakota         False  \n",
       "4   Monroe County       Florida         False  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_storm_2020.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8eb058a9-f187-4640-9afb-4d584a9652cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading tornados file for 2015.\n",
      "Considering file  tvs-2015.csv.gz\n",
      "Getting the response from the URL .....\n",
      "Downloaded succesfully\n",
      "Saved in folder\n",
      "WARNING *** file size (73412) not 512 + multiple of sector size (512)\n",
      "Downloading tornados file for 2016.\n",
      "Considering file  tvs-2016.csv.gz\n",
      "Getting the response from the URL .....\n",
      "Downloaded succesfully\n",
      "Saved in folder\n",
      "WARNING *** file size (73412) not 512 + multiple of sector size (512)\n",
      "Downloading tornados file for 2017.\n",
      "Considering file  tvs-2017.csv.gz\n",
      "Getting the response from the URL .....\n",
      "Downloaded succesfully\n",
      "Saved in folder\n",
      "WARNING *** file size (69316) not 512 + multiple of sector size (512)\n",
      "Downloading tornados file for 2018.\n",
      "Considering file  tvs-2018.csv.gz\n",
      "Getting the response from the URL .....\n",
      "Downloaded succesfully\n",
      "Saved in folder\n",
      "WARNING *** file size (86212) not 512 + multiple of sector size (512)\n",
      "Downloading tornados file for 2019.\n",
      "Considering file  tvs-2019.csv.gz\n",
      "file already exists\n",
      "WARNING *** file size (96452) not 512 + multiple of sector size (512)\n",
      "Downloading tornados file for 2020.\n",
      "Considering file  tvs-2020.csv.gz\n",
      "file already exists\n",
      "WARNING *** file size (120004) not 512 + multiple of sector size (512)\n",
      "Downloading tornados file for 2021.\n",
      "Considering file  tvs-2021.csv.gz\n",
      "Getting the response from the URL .....\n",
      "Downloaded succesfully\n",
      "Saved in folder\n",
      "WARNING *** file size (133828) not 512 + multiple of sector size (512)\n",
      "Downloading tornados file for 2022.\n",
      "Considering file  tvs-2022.csv.gz\n",
      "Getting the response from the URL .....\n",
      "Downloaded succesfully\n",
      "Saved in folder\n",
      "WARNING *** file size (134340) not 512 + multiple of sector size (512)\n",
      "CPU times: user 46.5 s, sys: 928 ms, total: 47.5 s\n",
      "Wall time: 1min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for year in range(2015,2023):\n",
    "    merged_tornado = merge(year,'tornados')\n",
    "    merged_tornado.to_csv(f'../../merged/merged_tornado_{year}.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a13d5f8f-1092-4b48-8778-04db0f20e0a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading mesocyclone file for 2015.\n",
      "Considering file  mda-2015.csv.gz\n",
      "file already exists\n",
      "WARNING *** file size (73412) not 512 + multiple of sector size (512)\n",
      "Downloading mesocyclone file for 2016.\n",
      "Considering file  mda-2016.csv.gz\n",
      "Getting the response from the URL .....\n",
      "Downloaded succesfully\n",
      "Saved in folder\n",
      "WARNING *** file size (73412) not 512 + multiple of sector size (512)\n",
      "Downloading mesocyclone file for 2017.\n",
      "Considering file  mda-2017.csv.gz\n",
      "Getting the response from the URL .....\n",
      "Downloaded succesfully\n",
      "Saved in folder\n",
      "WARNING *** file size (69316) not 512 + multiple of sector size (512)\n",
      "Downloading mesocyclone file for 2018.\n",
      "Considering file  mda-2018.csv.gz\n",
      "Getting the response from the URL .....\n",
      "Downloaded succesfully\n",
      "Saved in folder\n",
      "WARNING *** file size (86212) not 512 + multiple of sector size (512)\n",
      "Downloading mesocyclone file for 2019.\n",
      "Considering file  mda-2019.csv.gz\n",
      "file already exists\n",
      "WARNING *** file size (96452) not 512 + multiple of sector size (512)\n",
      "Downloading mesocyclone file for 2020.\n",
      "Considering file  mda-2020.csv.gz\n",
      "file already exists\n",
      "WARNING *** file size (120004) not 512 + multiple of sector size (512)\n",
      "Downloading mesocyclone file for 2021.\n",
      "Considering file  mda-2021.csv.gz\n",
      "Getting the response from the URL .....\n",
      "Downloaded succesfully\n",
      "Saved in folder\n",
      "WARNING *** file size (133828) not 512 + multiple of sector size (512)\n",
      "Downloading mesocyclone file for 2022.\n",
      "Considering file  mda-2022.csv.gz\n",
      "Getting the response from the URL .....\n",
      "Downloaded succesfully\n",
      "Saved in folder\n",
      "WARNING *** file size (134340) not 512 + multiple of sector size (512)\n",
      "CPU times: user 14min 27s, sys: 5.92 s, total: 14min 33s\n",
      "Wall time: 14min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for year in range(2015,2023):\n",
    "    merged_meso = merge(year,'mesocyclone')\n",
    "    merged_meso.to_csv(f'../../merged/merged_meso_{year}.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "14f3dd2f-c7e4-42ae-b6d5-70fa69795144",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading lightning file for 2015.\n",
      "Considering file  nldn-tiles-2015.csv.gz\n",
      "file already exists\n",
      "WARNING *** file size (73412) not 512 + multiple of sector size (512)\n",
      "Downloading lightning file for 2016.\n",
      "Considering file  nldn-tiles-2016.csv.gz\n",
      "file already exists\n",
      "WARNING *** file size (73412) not 512 + multiple of sector size (512)\n",
      "Downloading lightning file for 2017.\n",
      "Considering file  nldn-tiles-2017.csv.gz\n",
      "file already exists\n",
      "WARNING *** file size (69316) not 512 + multiple of sector size (512)\n",
      "Downloading lightning file for 2018.\n",
      "Considering file  nldn-tiles-2018.csv.gz\n",
      "file already exists\n",
      "WARNING *** file size (86212) not 512 + multiple of sector size (512)\n",
      "Downloading lightning file for 2019.\n",
      "Considering file  nldn-tiles-2019.csv.gz\n",
      "file already exists\n",
      "WARNING *** file size (96452) not 512 + multiple of sector size (512)\n",
      "Downloading lightning file for 2020.\n",
      "Considering file  nldn-tiles-2020.csv.gz\n",
      "file already exists\n",
      "WARNING *** file size (120004) not 512 + multiple of sector size (512)\n",
      "Downloading lightning file for 2021.\n",
      "Considering file  nldn-tiles-2021.csv.gz\n",
      "file already exists\n",
      "WARNING *** file size (133828) not 512 + multiple of sector size (512)\n",
      "Downloading lightning file for 2022.\n",
      "Considering file  nldn-tiles-2022.csv.gz\n",
      "file already exists\n",
      "WARNING *** file size (134340) not 512 + multiple of sector size (512)\n",
      "CPU times: user 30min 8s, sys: 11.4 s, total: 30min 19s\n",
      "Wall time: 30min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for year in range(2015,2023):\n",
    "    merged_lightning = merge(year,'lightning')\n",
    "    merged_lightning.to_csv(f'../../merged/merged_lightning_{year}.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85ff409-8ee3-492f-94af-e33062bdbdd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
